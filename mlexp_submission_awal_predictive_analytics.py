# -*- coding: utf-8 -*-
"""MLExp: Submission Awal-Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MYdJARVaD-GXpf7tDPW7zCykOpXMiq9Y

## Business Understanding

### 1. Problem Statements (Pernyataan Masalah)
Dalam dunia pendidikan, banyak faktor yang berkontribusi terhadap pencapaian akademik siswa. Namun, tidak semua faktor ini terlihat jelas, dan sulit bagi pendidik untuk mengetahui dengan pasti faktor mana yang paling berpengaruh terhadap nilai siswa. Masalah ini muncul dalam pertanyaa, seperti:
- Apa saja faktor yang dapat mempengaruhi nilai akademis siswa?
- Apakah kegiatan siswa di luar sekolah, seperti ekstrakulikuler, olahraga, musik dan menjadi volunteer memiliki dampak positif terhadap prestasi akademis siswa?
- Apakah dukungan dari orang tua berpengaruh terhadap nilai akademis siswa?
- Bagaimana peran bimbingan belajar dalam mempengaruhi nilai akademis siswa?
- Bisakah kita membuat model prediksi yang akurat untuk memprediksi GPA siswa berdasarkan data pendukung yang ada?

#### 2. Goals (Tujuan)
Tujuan utama dari proyek analisis prediktif ini adalah untuk menjawab pertanyaan-pertanyaan di atas, beberapa tujuan spesifik yang ingin dicapai adalah sebagai berikut:
- Mengidentifikasi faktor-faktor yang dapat mempengaruhi nilai akademis siswa
- Menmeriksa faktor seperti kegiatan siswa di luar sekolah, seperti ekstrakulikuler, olahraga, musik dan menjadi volunteer memiliki dampak positif terhadap prestasi akademis siswa
- Mengetahui pengaruh dukungan dari orang tua terhadap nilai akademis siswa
- Melihat peran bimbingan belajar terhadap nilai akademis siswa
- Membuat model prediksi yang akurat untuk memprediksi GPA siswa berdasarkan data pendukung yang ada

## Data Understanding

Dataset berisi 2.392 baris dan 15 kolom, dataset terdiri dari Id siswa, demografi siswa (usia, gender, etnis, pendidikan terakhir oranb tua), jam belajar mingguan, jumlah absen dalam setahun, status memakai tutor, dukungan orang tua, kegiatan ekstrakurikuler, kegiatan musik, kegiatan olahraga, kegiatan relawan, nilai, dan kelas. Target dari prediksi ini yaitu gpa predictive, atau prediksi nilai yang akan diraih. Kondisi data sudah bersih dari outliers dan missing values.

Referensi:
Rabie El Kharoua. "ðŸ“š Students Performance Dataset ðŸ“š". Tautan: https://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset. Diakses pada 12 Oktober 2024

## Data Loading
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# load the dataset
url = '/content/Student_performance_data _.csv'
gpa = pd.read_csv(url)
gpa

"""- Ada 2.392 baris (records atau jumlah pengamatan) dalam dataset.
- Terdapat 15 kolom yaitu: StudentID, Age, Gender, Ethnicity, ParentalEducation, StudyTimeWeekly, Absences, Tutoring, ParentalSupport, Extracurricular, Sports, Music, Volunteering, GPA, GradeClass

## Exploratory Data Analysis - Deskripsi Variabel

Deskripsi variabel dataset:
- StudentID : id tiap siswa dengan rentang 1001 - 3392
- Age : usia siswa dengan rentang 15 - 18 tahun
- Gender : jenis kelamin siswa (0: laki-laki, 1: perempuan)
- Ethnicity : etnis siswa (0: Kaukasia, 1: Afrika-Amerika, 2: Asia 3: Lainnya)
- ParentalEducation : tingkat pendidikan terakhir orang tua (0: tidak ada, 1: SMA, 2: beberapa perguruan tinggi, 3: sarjana, 4: lebih tinggi)
- StudyTimeWeekly : waktu belajar mingguan dalam satuan jam dengan rentang dari 0 - 20 jam
- Absences : jumlah ketidakhadiran atau absen selama tahun ajaran dengan rentang dari 0 - 30.
- Tutoring : status bimbingan belajar (0: tidak dan 1: ya)
- ParentalSupport : tingkat dukungan orang tua (0: tidak ada, 1: rendah, 2: sedang, 3: tinggi, 4: sangat tinggi)
Extracurricular : partisipasi dalam kegiatan ekstrakulikuler (0: tidak, 1: ya)
- Sports : partisipasi dalam kegiatan olahraga (0: tidak, 1: ya)
- Music : partisipasi dalam kegiatan musik (0: tidak, 1: ya)
- Volunteering : partisipasi dalam kegiatan sukarelawan (0: tidak, 1: ya)
- GPA : nilai ipk dengan rentang 0.0 - 4.0
- GradeClass : klasifikasi nilai siswa dari GPA (0: 'A' (IPK >= 3,5), 1: 'B' (3.0 <= IPK < 3.5), 2: 'C' (2.5 <= IPK < 3.0), 3: 'D' (2.0 <= IPK < 2.5), 4: 'F' (IPK < 2.0))
"""

gpa.info()

"""Dari output terlihat bahwa:

- Terdapat 11 kolom dengan tipe int64, yaitu: cut, color, dan clarity. Kolom ini merupakan categorical features (faktor non-numerik).
- Terdapat 3 kolom numerik dengan tipe data float64 yaitu: StudyTimeWeekly, GPA, GradeClass
- Terdapat 1 kolom numerik dengan tipe data int64, yaitu: price. Kolom ini merupakan target faktor kita.
"""

gpa.describe()

"""## Memeriksa Missing Value"""

gpa.duplicated().sum()

"""Dari hasil pemeriksaan missing value, dapat dilihat data sudah bersih dari missing value

## Memeriksa Outliers
"""

sns.boxplot(x=gpa['StudyTimeWeekly'])

sns.boxplot(x=gpa['Absences'])

"""Dapat dilihat, data juga sudah bersih dari outliers"""

gpa.dtypes

"""## Univariate Analysis"""

numerical_features = ['Age', 'StudyTimeWeekly', 'Absences', 'GPA']
categorical_features = ['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring', 'ParentalSupport', 'Extracurricular',
                        'Sports', 'Music', 'Volunteering', 'GradeClass']

"""##### Categorical Features"""

count = gpa['Gender'].value_counts()
percent = 100*gpa['Gender'].value_counts(normalize=True)
gpa_gender = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_gender)
count.plot(kind='bar', title='Gender');

"""Terdapat 2 kategori pada Gender, secara berurutan dari jumlahnya yang paling banyak yaitu: Laki-Laki. Dari data persentase dapat kita simpulkan bahwa 51.1% data adalah laki-laki."""

count = gpa['Ethnicity'].value_counts()
percent = 100*gpa['Ethnicity'].value_counts(normalize=True)
gpa_ethnic = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_ethnic)
count.plot(kind='bar', title='Ethnicity');

"""Terdapat 4 kategori pada Gender, secara berurutan dari jumlahnya yang paling banyak yaitu: Kaukasian, dan yang paling sedikit adalah lainnya

"""

count = gpa['ParentalEducation'].value_counts()
percent = 100*gpa['ParentalEducation'].value_counts(normalize=True)
gpa_predu = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_predu)
count.plot(kind='bar', title='Parental Education');

"""Terdapat 5 kategori pada ParentalEducation, secara berurutan dari jumlahnya yang paling banyak yaitu: lulusan beberapa perguruan tinggi, lalu disusul oleh lulusan SMA"""

count = gpa['Tutoring'].value_counts()
percent = 100*gpa['Tutoring'].value_counts(normalize=True)
gpa_tutor = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_tutor)
count.plot(kind='bar', title='Tutoring');

"""Terdapat 2 kategori pada Tutoring, secara berurutan dari jumlahnya yang paling banyak yaitu: 0, atau lebih banyak siswa yang tidak mengambil bimbingan belajar"""

count = gpa['ParentalSupport'].value_counts()
percent = 100*gpa['ParentalSupport'].value_counts(normalize=True)
gpa_prsupport = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_prsupport)
count.plot(kind='bar', title='Parental Support');

"""Terdapat 5 kategori pada ParentalSupport, secara berurutan dari jumlahnya yang paling banyak yaitu: 2 atau dukungan sedang, lalu disusul 3 atau dukungan tinggi, dan di urutan terakhir 0 atau dukungan rendah."""

count = gpa['Extracurricular'].value_counts()
percent = 100*gpa['Extracurricular'].value_counts(normalize=True)
gpa_extra = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_extra)
count.plot(kind='bar', title='Extracurricular');

"""Terdapat 2 kategori pada Ekstrakulikuler, secara berurutan dari jumlahnya yang paling banyak yaitu: 0, atau lebih banyak siswa tidak menngikuti kegiatan esktrakulikuler"""

count = gpa['Sports'].value_counts()
percent = 100*gpa['Sports'].value_counts(normalize=True)
gpa_sports = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_sports)
count.plot(kind='bar', title='Sports');

"""Terdapat 2 kategori pada Sports, secara berurutan dari jumlahnya yang paling banyak yaitu: 0, atau lebih banyak siswa yang tidak mengikuti olahraga"""

count = gpa['Music'].value_counts()
percent = 100*gpa['Music'].value_counts(normalize=True)
gpa_music = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_music)
count.plot(kind='bar', title='Music');

"""Terdapat 2 kategori pada Music, secara berurutan dari jumlahnya yang paling banyak yaitu: 0, atau lebih banyak siswa yang tidak mengikuti musik"""

count = gpa['Volunteering'].value_counts()
percent = 100*gpa['Volunteering'].value_counts(normalize=True)
gpa_volun = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_volun)
count.plot(kind='bar', title='Volunteering');

"""Terdapat 2 kategori pada Volunteering, secara berurutan dari jumlahnya yang paling banyak yaitu: 0, atau lebih banyak yang tidak mengikuti kegiatan volunteering"""

count = gpa['GradeClass'].value_counts()
percent = 100*gpa['GradeClass'].value_counts(normalize=True)
gpa_grclass = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(gpa_grclass)
count.plot(kind='bar', title='Grade Class');

"""Terdapat 5 kategori pada Gender, secara berurutan dari jumlahnya yang paling banyak yaitu: 4, atau lebih banyak siswa yang memiliki GPA F atau di bawah 2.0

#### Numerical Features
"""

gpa.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari histogram "GPA", kita bisa memperoleh beberapa informasi, antara lain:

- Peningkatan harga diamonds tertinggi berada di sekitar 1.5, hal ini cukup disayangkan karena masih tergolong F atau cukup rendah
- Masih cukup sedikit siswa yang memiliki GPA di sekitar 3 sampai 4

## Exploratory Data Analysis - Multivariate Analysis

#### Categorical Features
"""

gpa

gpa_cat = gpa[['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring', 'ParentalSupport', 'Extracurricular',
               'Sports', 'Music', 'Volunteering', 'GradeClass']]
gpa_cat

#mengecek rata-rata harga terhadap tiap-tiap faktor, untuk mengetahui seberapa berpengaruhnya

for col in gpa_cat:
  sns.catplot(x=col, y="GPA", kind="bar", dodge=False, height = 4, aspect = 3,  data=gpa, palette="Set3")
  plt.title("Rata-rata 'GPA' Relatif terhadap - {}".format(col))
  plt.show()

"""Dengan mengamati rata-rata GPA relatif terhadap faktor kategori di atas, kita memperoleh insight sebagai berikut:

- Pada faktor Gender, rata-ratanya hampir sama. Sehingga, faktor ini tidak memiliki pengaruh signifikan terhadap GPA
- Pada faktor EThnicity, rata-rata yang dihasilkan juga hampir tidak jauh berbeda pada keempat jenis etnis. Sehingga, faktor ini juga tidak memiliki pengaruh signifikan terhadap GPA
- Pada faktor ParentalEducation, rata-rata yang dihasilkan juga hampir tidak jauh berbeda pada keempat jenis etnis. Sehingga, faktor ini juga tidak memiliki pengaruh signifikan terhadap GPA
- Pada faktor Tutoring, rata-rata yang dihasilkan oleh 1 (atau memakai bimbel) lebih tinggi. Sehingga, faktor ini memiliki pengaruh signifikan terhadap GPA
- Pada faktor ParentalSupport, rata-rata yang dihasilkan berbanding lurus dengan kenaikan GPA. Semakin tinggi nilainya, GPA juga meningkat. Sehingga, faktor ini memiliki pengaruh signifikan terhadap GPA
- Pada faktor Extraculiculler, Sports dan Music, rata-rata yang dihasilkan oleh 1 (atau status = ya) lebih tinggi. Sehingga, ketiga faktor ini memiliki pengaruh signifikan terhadap GPA
- Pada faktor Volunteering, rata-rata yang dihasilkan jhampir sama. Sehingga, faktor ini juga tidak memiliki pengaruh signifikan terhadap GPA
- Pada faktor GradeClass, rata-rata yang dihasilkan tidak begitu pengaruh, karena memang pada dasarnya Grade Class adalah bentuk lain dari GPA.


Kesimpulan: Tutoring, ParentalSupport, Extraculiculler, Sports dan Music adalah faktor faktor yang berpengaruh terhadap GPA
"""

#Faktor yang tidak berpengaruh didrop
gpa.drop(['Gender'], inplace=True, axis=1)
gpa.drop(['Ethnicity'], inplace=True, axis=1)
gpa.drop(['ParentalEducation'], inplace=True, axis=1)
gpa.drop(['Volunteering'], inplace=True, axis=1)
gpa.drop(['GradeClass'], inplace=True, axis=1)
gpa

"""#### Numerical Features"""

gpa_num = gpa[['Age', 'StudyTimeWeekly', 'Absences', 'GPA']]
gpa_num

# Mengamati hubungan antar faktor numerik dengan fungsi pairplot(), untuk mengetahui korelasi antara harga dan tiap faktor
sns.pairplot(gpa_num, diag_kind = 'kde')

"""Pada pola sebaran data grafik pairplot sebelumnya, terlihat Absences dan StudyTimeWeekly memiliki korelasi yang tinggi dengan faktor GPA. Sedangkan kedua faktor Age terlihat memiliki korelasi yang lemah karena sebarannya tidak membentuk pola,"""

plt.figure(figsize=(10, 8))
correlation_matrix = gpa_num.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk faktor Numerik ", size=20)

"""Faktor Absences (-0.92) dan StudyTimeWeekly (0.18) memiliki skor korelasi yang besar dengan faktor target GPA. Artinya, faktor GPA berkorelasi tinggi dengan  faktor tersebut. Sementara itu, faktor Age memiliki korelasi yang sangat kecil (0). Sebenarnya, jika dilihat dari heatmap, faktor Absence memiliki korelasi yang rendah, tetapi karena faktor ini membentuk pola pada scatterplot sebelumnya, maka faktor ini dipertahankan"""

#Karena Age memiliki korelasi rendah, maka ia di drop
gpa.drop(['Age'], inplace=True, axis=1)
gpa

"""## Data Preparation

#### Reduksi Dimensi dengan PCA

Teknik reduksi (pengurangan) dimensi adalah prosedur yang mengurangi jumlah faktor dengan tetap mempertahankan informasi pada data. Teknik pengurangan dimensi yang paling populer adalah Principal Component Analysis atau disingkat menjadi PCA. Ia adalah teknik untuk mereduksi dimensi, mengekstraksi faktor, dan mentransformasi data dari â€œn-dimensional spaceâ€ ke dalam sistem berkoordinat baru dengan dimensi m, di mana m lebih kecil dari n.
"""

sns.pairplot(gpa[['StudyTimeWeekly','Absences', 'GPA']], plot_kws={'s':3});

from sklearn.decomposition import PCA

pca = PCA(n_components=3, random_state=123)
pca.fit(gpa[['StudyTimeWeekly','Absences', 'GPA']])
princ_comp = pca.transform(gpa[['StudyTimeWeekly','Absences', 'GPA']])

#mengetahui proporsi informasi dari ketiga komponen
pca.explained_variance_ratio_.round(3)

#membuat faktor baru bernama 'dimension' untuk menggantikan faktor faktor 'StudyTimeWeekly','Absences', 'GPA'
from sklearn.decomposition import PCA

pca = PCA(n_components=1, random_state=123)
pca.fit(gpa[['StudyTimeWeekly','Absences', 'GPA']])
gpa['dimension'] = pca.transform(gpa.loc[:, ('StudyTimeWeekly','Absences', 'GPA')]).flatten()

gpa

"""## Train-Test-Split"""

from sklearn.model_selection import train_test_split

X = gpa.drop(["GPA"],axis =1)
y = gpa["GPA"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""Membagi dataset menjadi 80% data train dan 20% data uji"""



"""## Standarisasi

StandardScaler melakukan proses standarisasi faktor dengan mengurangkan mean (nilai rata-rata) kemudian membaginya dengan standar deviasi untuk menggeser distribusi.  StandardScaler menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0. Sekitar 68% dari nilai akan berada di antara -1 dan 1.
"""

print(X_train.columns)

from sklearn.preprocessing import StandardScaler

numerical_features = ['Tutoring',	'ParentalSupport',	'Extracurricular',	'Sports',	'Music']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features]

#mengecek nilai mean dan standar deviasi pada setelah proses standarisasi

X_train[numerical_features].describe().round(4)

X_train

"""## Model Development dengan K-Nearest Neighbor

KNN bekerja dengan membandingkan jarak satu sampel ke sampel pelatihan lain dengan memilih sejumlah k tetangga terdekat (dengan k adalah sebuah angka positif). Dengan kata lain, setiap data baru diberi nilai berdasarkan seberapa mirip titik tersebut dalam set pelatihan.
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=10) #menggunakan k = 10 tetangga dan metric Euclidean untuk mengukur jarak antara titik
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""## Model Development dengan Random Forest

Random forest merupakan salah satu model machine learning yang termasuk ke dalam kategori ensemble (group) learning. Apa itu model ensemble? Sederhananya, ia merupakan model prediksi yang terdiri dari beberapa model dan bekerja secara bersama-sama. Ide dibalik model ensemble adalah sekelompok model yang bekerja bersama menyelesaikan masalah. Sehingga, tingkat keberhasilan akan lebih tinggi dibanding model yang bekerja sendirian. Pada model ensemble, setiap model harus membuat prediksi secara independen. Kemudian, prediksi dari setiap model ensemble ini digabungkan untuk membuat prediksi akhir.

Gabungan dari metode decision tree disebut dengan random forest.

Misalnya, ada 100 model decision tree pada bag random forest kita, ini berarti bahwa keputusan (decision) yang dibuat oleh setiap pohon (model) akan sangat bervariasi, pada kasus regresi, prediksi akhir adalah rata-rata prediksi seluruh pohon dalam model ensemble.
"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""- n_estimator: jumlah trees (pohon) di forest. Di sini kita set n_estimator=50.
- max_depth: kedalaman atau panjang pohon. Ia merupakan ukuran seberapa banyak pohon dapat membelah (splitting) untuk membagi setiap node ke dalam jumlah pengamatan yang diinginkan.
- random_state: digunakan untuk mengontrol random number generator yang digunakan.
- n_jobs: jumlah job (pekerjaan) yang digunakan secara paralel. Ia merupakan komponen untuk mengontrol thread atau proses yang berjalan secara paralel. n_jobs=-1 artinya semua proses berjalan secara paralel.

## Model Development dengan Boosting Algorithm

Seperti namanya, boosting, algoritma ini bertujuan untuk meningkatkan performa atau akurasi prediksi. Caranya adalah dengan menggabungkan beberapa model sederhana dan dianggap lemah (weak learners) sehingga membentuk suatu model yang kuat (strong ensemble learner). Algoritma boosting muncul dari gagasan mengenai apakah algoritma yang sederhana seperti linear regression dan decision tree dapat dimodifikasi untuk dapat meningkatkan performa.
"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""- learning_rate: bobot yang diterapkan pada setiap regressor di masing-masing proses iterasi boosting.
- random_state: digunakan untuk mengontrol random number generator yang digunakan.

## Evaluasi
"""

# Lakukan scaling terhadap faktor numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test, membaginya ke dalam 1e3 agar skalanya tdk trllu besar
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari gambar di atas, terlihat bahwa, model Random Forest (RF) memberikan nilai eror yang paling kecil. Sedangkan model dengan algoritma KNN memiliki eror yang paling besar. Sehingga model RF yang akan kita pilih sebagai model terbaik untuk melakukan prediksi harga diamonds"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
  pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Terlihat bahwa prediksi dengan Random Forest (RF) memberikan hasil yang paling mendekati"""

prediksi = X_test.iloc[:10].copy()
pred_dict = {'y_true':y_test[:10]}
for name, model in model_dict.items():
  pred_dict['prediksi_'+name] = model.predict(prediksi).round(3)

pd.DataFrame(pred_dict)

gpa

